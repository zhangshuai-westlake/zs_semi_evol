{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e02f282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:58:04.774833Z",
     "start_time": "2025-01-10T17:58:04.366256Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "from common import format_multichoice_question, extract_result\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e327e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 验证数据重复\n",
    "\n",
    "from datasets import load_dataset\n",
    "ck_ds = load_dataset(\"cais/mmlu\", \"clinical_knowledge\")\n",
    "ck_df = pd.DataFrame(ck_ds[\"test\"])\n",
    "cm_ds = load_dataset(\"cais/mmlu\", \"college_medicine\")\n",
    "cm_df = pd.DataFrame(cm_ds[\"test\"])\n",
    "\n",
    "ck_df[\"instruction\"] = ck_df.apply(\n",
    "    lambda row: row[\"question\"] + \"\".join(row[\"choices\"]), axis=1\n",
    ")\n",
    "\n",
    "cm_df[\"instruction\"] = cm_df.apply(\n",
    "    lambda row: row[\"question\"] + \"\".join(row[\"choices\"]), axis=1\n",
    ")\n",
    "\n",
    "pd.merge(\n",
    "    ck_df, cm_df, on=\"instruction\", how=\"inner\", suffixes=('_unlabed', '_test')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be83c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:58:06.643719Z",
     "start_time": "2025-01-10T17:58:06.641111Z"
    },
    "code_folding": [
     0,
     9,
     17
    ]
   },
   "outputs": [],
   "source": [
    "def format_question_alpaca(row, format_fn=format_multichoice_question):\n",
    "    input_text = format_fn(row)\n",
    "    output_test = f'Answer: {row[\"answer\"]}'\n",
    "    return {\n",
    "        \"instruction\": input_text,\n",
    "        \"input\": '',\n",
    "        \"output\": output_test\n",
    "    }\n",
    "\n",
    "def format_qa_gpt(row, format_fn=format_multichoice_question):\n",
    "    return {\n",
    "        'messages': [\n",
    "            {\"role\": \"user\", \"content\": format_fn(row)},\n",
    "            {\"role\": \"assistant\", \"content\": \"Answer: \" + row[\"answer\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def append_info(df, subtask_name, instruction_to_row):\n",
    "    df[subtask_name] = df.apply(lambda row: instruction_to_row[row[\"instruction\"]][subtask_name], axis=1)\n",
    "    df[\"from\"] = df.apply(lambda row: instruction_to_row[row[\"instruction\"]][\"from\"], axis=1)\n",
    "    df[\"answer\"] = df.apply(lambda row: instruction_to_row[row[\"instruction\"]][\"answer\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14afafbc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 原数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f5ed40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:58:19.197564Z",
     "start_time": "2025-01-10T17:58:17.830171Z"
    },
    "code_folding": [
     8,
     12,
     20,
     24
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12032it [00:00, 20916.48it/s]\n",
      "7219it [00:00, 20007.26it/s]\n",
      "2406it [00:00, 15930.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labeled_count</th>\n",
       "      <th>labeled_proportion</th>\n",
       "      <th>unlabeled_count</th>\n",
       "      <th>unlabeled_proportion</th>\n",
       "      <th>test_count</th>\n",
       "      <th>test_proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biology</th>\n",
       "      <td>159</td>\n",
       "      <td>0.066085</td>\n",
       "      <td>422</td>\n",
       "      <td>0.058457</td>\n",
       "      <td>136</td>\n",
       "      <td>0.056502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>158</td>\n",
       "      <td>0.065669</td>\n",
       "      <td>485</td>\n",
       "      <td>0.067184</td>\n",
       "      <td>146</td>\n",
       "      <td>0.060656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemistry</th>\n",
       "      <td>218</td>\n",
       "      <td>0.090607</td>\n",
       "      <td>686</td>\n",
       "      <td>0.095027</td>\n",
       "      <td>228</td>\n",
       "      <td>0.094724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer science</th>\n",
       "      <td>73</td>\n",
       "      <td>0.030341</td>\n",
       "      <td>250</td>\n",
       "      <td>0.034631</td>\n",
       "      <td>87</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economics</th>\n",
       "      <td>181</td>\n",
       "      <td>0.075229</td>\n",
       "      <td>497</td>\n",
       "      <td>0.068846</td>\n",
       "      <td>166</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineering</th>\n",
       "      <td>172</td>\n",
       "      <td>0.071488</td>\n",
       "      <td>598</td>\n",
       "      <td>0.082837</td>\n",
       "      <td>199</td>\n",
       "      <td>0.082676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>184</td>\n",
       "      <td>0.076475</td>\n",
       "      <td>461</td>\n",
       "      <td>0.063859</td>\n",
       "      <td>173</td>\n",
       "      <td>0.071874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history</th>\n",
       "      <td>75</td>\n",
       "      <td>0.031172</td>\n",
       "      <td>230</td>\n",
       "      <td>0.031860</td>\n",
       "      <td>76</td>\n",
       "      <td>0.031575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>law</th>\n",
       "      <td>218</td>\n",
       "      <td>0.090607</td>\n",
       "      <td>677</td>\n",
       "      <td>0.093780</td>\n",
       "      <td>206</td>\n",
       "      <td>0.085584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math</th>\n",
       "      <td>274</td>\n",
       "      <td>0.113882</td>\n",
       "      <td>825</td>\n",
       "      <td>0.114282</td>\n",
       "      <td>252</td>\n",
       "      <td>0.104695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>197</td>\n",
       "      <td>0.081879</td>\n",
       "      <td>533</td>\n",
       "      <td>0.073833</td>\n",
       "      <td>194</td>\n",
       "      <td>0.080598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philosophy</th>\n",
       "      <td>101</td>\n",
       "      <td>0.041978</td>\n",
       "      <td>292</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>106</td>\n",
       "      <td>0.044038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physics</th>\n",
       "      <td>246</td>\n",
       "      <td>0.102244</td>\n",
       "      <td>790</td>\n",
       "      <td>0.109433</td>\n",
       "      <td>263</td>\n",
       "      <td>0.109265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psychology</th>\n",
       "      <td>150</td>\n",
       "      <td>0.062344</td>\n",
       "      <td>473</td>\n",
       "      <td>0.065522</td>\n",
       "      <td>175</td>\n",
       "      <td>0.072705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  labeled_count  labeled_proportion  unlabeled_count  \\\n",
       "category                                                               \n",
       "biology                     159            0.066085              422   \n",
       "business                    158            0.065669              485   \n",
       "chemistry                   218            0.090607              686   \n",
       "computer science             73            0.030341              250   \n",
       "economics                   181            0.075229              497   \n",
       "engineering                 172            0.071488              598   \n",
       "health                      184            0.076475              461   \n",
       "history                      75            0.031172              230   \n",
       "law                         218            0.090607              677   \n",
       "math                        274            0.113882              825   \n",
       "other                       197            0.081879              533   \n",
       "philosophy                  101            0.041978              292   \n",
       "physics                     246            0.102244              790   \n",
       "psychology                  150            0.062344              473   \n",
       "\n",
       "                  unlabeled_proportion  test_count  test_proportion  \n",
       "category                                                             \n",
       "biology                       0.058457         136         0.056502  \n",
       "business                      0.067184         146         0.060656  \n",
       "chemistry                     0.095027         228         0.094724  \n",
       "computer science              0.034631          87         0.036145  \n",
       "economics                     0.068846         166         0.068966  \n",
       "engineering                   0.082837         199         0.082676  \n",
       "health                        0.063859         173         0.071874  \n",
       "history                       0.031860          76         0.031575  \n",
       "law                           0.093780         206         0.085584  \n",
       "math                          0.114282         252         0.104695  \n",
       "other                         0.073833         194         0.080598  \n",
       "philosophy                    0.040449         106         0.044038  \n",
       "physics                       0.109433         263         0.109265  \n",
       "psychology                    0.065522         175         0.072705  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task = \"mmlu\"\n",
    "# subtask_name = \"Subject\"\n",
    "task = \"mmlu_pro\"\n",
    "subtask_name = \"category\"\n",
    "\n",
    "path = f\"../data/{task}/labeled.csv\"\n",
    "labeled_raw_df = pd.read_csv(path)\n",
    "labeled_raw_df[\"from\"] = \"labeled\"\n",
    "labeled_raw_df[\"instruction\"] = labeled_raw_df.apply(\n",
    "    lambda row: format_question_alpaca(row, format_multichoice_question)[\"instruction\"], axis=1\n",
    ")\n",
    "labeled_summary_df = labeled_raw_df.groupby(subtask_name).agg(count=('answer', 'size'))\n",
    "labeled_summary_df[\"proportion\"] = labeled_summary_df.apply(\n",
    "    lambda row: row[\"count\"] / labeled_summary_df[\"count\"].sum(), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "path = f\"../data/{task}/unlabeled.csv\"\n",
    "unlabeled_raw_df = pd.read_csv(path)\n",
    "unlabeled_raw_df[\"from\"] = \"unlabeled\"\n",
    "unlabeled_raw_df[\"instruction\"] = unlabeled_raw_df.apply(\n",
    "    lambda row: format_question_alpaca(row, format_multichoice_question)[\"instruction\"], axis=1\n",
    ")\n",
    "unlabeled_summary_df = unlabeled_raw_df.groupby(subtask_name).agg(count=('answer', 'size'))\n",
    "unlabeled_summary_df[\"proportion\"] = unlabeled_summary_df.apply(\n",
    "    lambda row: row[\"count\"] / unlabeled_summary_df[\"count\"].sum(), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "path = f\"../data/{task}/test.csv\"\n",
    "test_raw_df = pd.read_csv(path)\n",
    "test_raw_df[\"from\"] = \"test\"\n",
    "test_raw_df[\"instruction\"] = test_raw_df.apply(\n",
    "    lambda row: format_question_alpaca(row, format_multichoice_question)[\"instruction\"], axis=1\n",
    ")\n",
    "test_summary_df = test_raw_df.groupby(subtask_name).agg(count=('answer', 'size'))\n",
    "test_summary_df[\"proportion\"] = test_summary_df.apply(\n",
    "    lambda row: row[\"count\"] / test_summary_df[\"count\"].sum(), axis=1\n",
    ")\n",
    "dfs = [\n",
    "    labeled_summary_df.add_prefix('labeled_'),\n",
    "    unlabeled_summary_df.add_prefix('unlabeled_'),\n",
    "    test_summary_df.add_prefix('test_')\n",
    "]\n",
    "summary_df = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=subtask_name, how='outer', suffixes=('_left', '_right')), dfs\n",
    ")\n",
    "\n",
    "raw_df = pd.concat([labeled_raw_df, unlabeled_raw_df, test_raw_df], axis=0, ignore_index=True)\n",
    "\n",
    "instruction_to_row = {\n",
    "    format_question_alpaca(row, format_multichoice_question)[\"instruction\"]: row \n",
    "    for _, row in tqdm(raw_df.iterrows())\n",
    "}\n",
    "unlabel_instruction_to_row = {\n",
    "    format_question_alpaca(row, format_multichoice_question)[\"instruction\"]: row \n",
    "    for _, row in tqdm(unlabeled_raw_df.iterrows())\n",
    "}\n",
    "label_instruction_to_row = {\n",
    "    format_question_alpaca(row, format_multichoice_question)[\"instruction\"]: row \n",
    "    for _, row in tqdm(labeled_raw_df.iterrows())\n",
    "}\n",
    "\n",
    "overlap_df = pd.merge(\n",
    "    unlabeled_raw_df, test_raw_df, on=\"instruction\", how=\"inner\", suffixes=('_unlabed', '_test')\n",
    ")\n",
    "\n",
    "# overlap_df = pd.merge(\n",
    "#     labeled_raw_df, test_raw_df, on=\"instruction\", how=\"inner\", suffixes=('_unlabed', '_test')\n",
    "# )\n",
    "\n",
    "summary_df\n",
    "# overlap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683557c7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 在unlabeled数据上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14dde8e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:58:24.135905Z",
     "start_time": "2025-01-10T17:58:23.725304Z"
    },
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>before_accuracy</th>\n",
       "      <th>after</th>\n",
       "      <th>after_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biology</th>\n",
       "      <td>422.0/0.0585</td>\n",
       "      <td>0.630</td>\n",
       "      <td>298/0.0825</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>485.0/0.0672</td>\n",
       "      <td>0.365</td>\n",
       "      <td>192/0.0532</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemistry</th>\n",
       "      <td>686.0/0.095</td>\n",
       "      <td>0.414</td>\n",
       "      <td>348/0.0964</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer science</th>\n",
       "      <td>250.0/0.0346</td>\n",
       "      <td>0.392</td>\n",
       "      <td>92/0.0255</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economics</th>\n",
       "      <td>497.0/0.0688</td>\n",
       "      <td>0.489</td>\n",
       "      <td>290/0.0803</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineering</th>\n",
       "      <td>598.0/0.0828</td>\n",
       "      <td>0.415</td>\n",
       "      <td>280/0.0776</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>461.0/0.0639</td>\n",
       "      <td>0.514</td>\n",
       "      <td>294/0.0814</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history</th>\n",
       "      <td>230.0/0.0319</td>\n",
       "      <td>0.439</td>\n",
       "      <td>152/0.0421</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>law</th>\n",
       "      <td>677.0/0.0938</td>\n",
       "      <td>0.312</td>\n",
       "      <td>279/0.0773</td>\n",
       "      <td>0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math</th>\n",
       "      <td>825.0/0.1143</td>\n",
       "      <td>0.314</td>\n",
       "      <td>282/0.0781</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>533.0/0.0738</td>\n",
       "      <td>0.360</td>\n",
       "      <td>267/0.074</td>\n",
       "      <td>0.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philosophy</th>\n",
       "      <td>292.0/0.0404</td>\n",
       "      <td>0.445</td>\n",
       "      <td>180/0.0499</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physics</th>\n",
       "      <td>790.0/0.1094</td>\n",
       "      <td>0.370</td>\n",
       "      <td>326/0.0903</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psychology</th>\n",
       "      <td>473.0/0.0655</td>\n",
       "      <td>0.586</td>\n",
       "      <td>330/0.0914</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        before  before_accuracy       after  after_accuracy\n",
       "category                                                                   \n",
       "biology           422.0/0.0585            0.630  298/0.0825           0.859\n",
       "business          485.0/0.0672            0.365  192/0.0532           0.641\n",
       "chemistry          686.0/0.095            0.414  348/0.0964           0.667\n",
       "computer science  250.0/0.0346            0.392   92/0.0255           0.739\n",
       "economics         497.0/0.0688            0.489  290/0.0803           0.728\n",
       "engineering       598.0/0.0828            0.415  280/0.0776           0.689\n",
       "health            461.0/0.0639            0.514  294/0.0814           0.711\n",
       "history           230.0/0.0319            0.439  152/0.0421           0.559\n",
       "law               677.0/0.0938            0.312  279/0.0773           0.523\n",
       "math              825.0/0.1143            0.314  282/0.0781           0.617\n",
       "other             533.0/0.0738            0.360   267/0.074           0.581\n",
       "philosophy        292.0/0.0404            0.445  180/0.0499           0.594\n",
       "physics           790.0/0.1094            0.370  326/0.0903           0.699\n",
       "psychology        473.0/0.0655            0.586  330/0.0914           0.776"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_init_df = pd.read_json(f\"../sft/data/{task}_labeled_alpaca.json\")\n",
    "# append_info(label_init_df, subtask_name=subtask_name, instruction_to_row=label_instruction_to_row)\n",
    "\n",
    "unlabeled_warm_df = pd.read_csv(f\"../data/{task}/pseudo_warm_llama3.1_{task}.csv\")\n",
    "unlabeled_warm_df[\"instruction\"] = unlabeled_warm_df.apply(\n",
    "    lambda row: format_question_alpaca(row, format_multichoice_question)[\"instruction\"], axis=1\n",
    ")\n",
    "unlabeled_warm_df[\"Accuracy2\"] = unlabeled_warm_df.apply(\n",
    "    lambda row: int(row[\"PseudoLabel\"] == row[\"answer\"]), axis=1\n",
    ")\n",
    "append_info(unlabeled_warm_df, subtask_name=subtask_name, instruction_to_row=unlabel_instruction_to_row)\n",
    "assert np.all(unlabeled_warm_df[\"Accuracy\"] == unlabeled_warm_df[\"Accuracy2\"])\n",
    "\n",
    "unlabeled_filter_df = pd.read_json(f\"../sft/data/pseudo_warm_llama3.1_{task}_alpaca.json\")\n",
    "append_info(unlabeled_filter_df, subtask_name=subtask_name, instruction_to_row=unlabel_instruction_to_row)\n",
    "unlabeled_filter_df[\"Accuracy2\"] = unlabeled_filter_df.apply(\n",
    "    lambda row: int(extract_result(row[\"output\"]) == row[\"answer\"]), axis=1)\n",
    "assert np.all(unlabeled_filter_df[\"Accuracy\"] == unlabeled_filter_df[\"Accuracy2\"])\n",
    "\n",
    "\n",
    "unlabeled_warm_summary_df = unlabeled_warm_df.groupby(subtask_name).agg(\n",
    "    count=('Accuracy', 'size'), accuracy=('Accuracy', 'mean')\n",
    ")\n",
    "unlabeled_warm_summary_df[\"proportion\"] = unlabeled_warm_summary_df.apply(\n",
    "    lambda row: row[\"count\"] / unlabeled_warm_summary_df[\"count\"].sum(), axis=1\n",
    ")\n",
    "\n",
    "unlabeled_filter_summary_df = unlabeled_filter_df.groupby(subtask_name).agg(\n",
    "    count=('Accuracy', 'size'), accuracy=('Accuracy', 'mean')\n",
    ")\n",
    "unlabeled_filter_summary_df[\"proportion\"] = unlabeled_filter_summary_df.apply(\n",
    "    lambda row: row[\"count\"] / unlabeled_filter_summary_df[\"count\"].sum(), axis=1\n",
    ")\n",
    "\n",
    "unlabeled_summary_df = pd.merge(\n",
    "    unlabeled_warm_summary_df.add_prefix(\"before_\"), \n",
    "    unlabeled_filter_summary_df.add_prefix(\"after_\"), \n",
    "    on=subtask_name, how='outer'\n",
    ")\n",
    "\n",
    "for prefix in [\"before\", \"after\"]: \n",
    "    unlabeled_summary_df[prefix] = unlabeled_summary_df.apply(\n",
    "        lambda row: f\"{row[f'{prefix}_count']}/{round(row[f'{prefix}_proportion'], 4)}\", axis=1\n",
    "    )\n",
    "    \n",
    "for prefix in [\"before\", \"after\"]:\n",
    "    unlabeled_summary_df[f\"{prefix}_accuracy\"] = unlabeled_summary_df.apply(\n",
    "        lambda row: round(row[f'{prefix}_accuracy'], 3), axis=1\n",
    "    )\n",
    "    \n",
    "unlabeled_show_summary_df = unlabeled_summary_df[[\n",
    "    \"before\", \"before_accuracy\", \n",
    "    \"after\", \"after_accuracy\", \n",
    "]]\n",
    "\n",
    "unlabeled_show_summary_df.to_csv(f\"result/{task}_unlabeled.csv\")\n",
    "\n",
    "unlabeled_show_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1297c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 在test集的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291ee62f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:58:30.456060Z",
     "start_time": "2025-01-10T17:58:30.342888Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>base_accuracy</th>\n",
       "      <th>warm</th>\n",
       "      <th>warm_accuracy</th>\n",
       "      <th>semievol_before_filter</th>\n",
       "      <th>semievol_after_filter</th>\n",
       "      <th>after/before</th>\n",
       "      <th>semievol_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biology</th>\n",
       "      <td>136.0/0.0565</td>\n",
       "      <td>0.669</td>\n",
       "      <td>159/0.0661</td>\n",
       "      <td>0.713</td>\n",
       "      <td>422/0.0585</td>\n",
       "      <td>298/0.0825</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>146.0/0.0607</td>\n",
       "      <td>0.466</td>\n",
       "      <td>158/0.0657</td>\n",
       "      <td>0.390</td>\n",
       "      <td>485/0.0672</td>\n",
       "      <td>192/0.0532</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemistry</th>\n",
       "      <td>228.0/0.0947</td>\n",
       "      <td>0.285</td>\n",
       "      <td>218/0.0906</td>\n",
       "      <td>0.443</td>\n",
       "      <td>686/0.095</td>\n",
       "      <td>348/0.0964</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer science</th>\n",
       "      <td>87.0/0.0361</td>\n",
       "      <td>0.345</td>\n",
       "      <td>73/0.0303</td>\n",
       "      <td>0.483</td>\n",
       "      <td>250/0.0346</td>\n",
       "      <td>92/0.0255</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economics</th>\n",
       "      <td>166.0/0.069</td>\n",
       "      <td>0.494</td>\n",
       "      <td>181/0.0752</td>\n",
       "      <td>0.536</td>\n",
       "      <td>497/0.0688</td>\n",
       "      <td>290/0.0803</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineering</th>\n",
       "      <td>199.0/0.0827</td>\n",
       "      <td>0.241</td>\n",
       "      <td>172/0.0715</td>\n",
       "      <td>0.492</td>\n",
       "      <td>598/0.0828</td>\n",
       "      <td>280/0.0776</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>173.0/0.0719</td>\n",
       "      <td>0.532</td>\n",
       "      <td>184/0.0765</td>\n",
       "      <td>0.584</td>\n",
       "      <td>461/0.0639</td>\n",
       "      <td>294/0.0814</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history</th>\n",
       "      <td>76.0/0.0316</td>\n",
       "      <td>0.447</td>\n",
       "      <td>75/0.0312</td>\n",
       "      <td>0.434</td>\n",
       "      <td>230/0.0319</td>\n",
       "      <td>152/0.0421</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>law</th>\n",
       "      <td>206.0/0.0856</td>\n",
       "      <td>0.291</td>\n",
       "      <td>218/0.0906</td>\n",
       "      <td>0.364</td>\n",
       "      <td>677/0.0938</td>\n",
       "      <td>279/0.0773</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math</th>\n",
       "      <td>252.0/0.1047</td>\n",
       "      <td>0.345</td>\n",
       "      <td>274/0.1139</td>\n",
       "      <td>0.341</td>\n",
       "      <td>825/0.1143</td>\n",
       "      <td>282/0.0781</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>194.0/0.0806</td>\n",
       "      <td>0.418</td>\n",
       "      <td>197/0.0819</td>\n",
       "      <td>0.448</td>\n",
       "      <td>533/0.0738</td>\n",
       "      <td>267/0.074</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philosophy</th>\n",
       "      <td>106.0/0.044</td>\n",
       "      <td>0.387</td>\n",
       "      <td>101/0.042</td>\n",
       "      <td>0.415</td>\n",
       "      <td>292/0.0404</td>\n",
       "      <td>180/0.0499</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physics</th>\n",
       "      <td>263.0/0.1093</td>\n",
       "      <td>0.297</td>\n",
       "      <td>246/0.1022</td>\n",
       "      <td>0.426</td>\n",
       "      <td>790/0.1094</td>\n",
       "      <td>326/0.0903</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psychology</th>\n",
       "      <td>175.0/0.0727</td>\n",
       "      <td>0.531</td>\n",
       "      <td>150/0.0623</td>\n",
       "      <td>0.589</td>\n",
       "      <td>473/0.0655</td>\n",
       "      <td>330/0.0914</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          test  base_accuracy        warm  warm_accuracy  \\\n",
       "category                                                                   \n",
       "biology           136.0/0.0565          0.669  159/0.0661          0.713   \n",
       "business          146.0/0.0607          0.466  158/0.0657          0.390   \n",
       "chemistry         228.0/0.0947          0.285  218/0.0906          0.443   \n",
       "computer science   87.0/0.0361          0.345   73/0.0303          0.483   \n",
       "economics          166.0/0.069          0.494  181/0.0752          0.536   \n",
       "engineering       199.0/0.0827          0.241  172/0.0715          0.492   \n",
       "health            173.0/0.0719          0.532  184/0.0765          0.584   \n",
       "history            76.0/0.0316          0.447   75/0.0312          0.434   \n",
       "law               206.0/0.0856          0.291  218/0.0906          0.364   \n",
       "math              252.0/0.1047          0.345  274/0.1139          0.341   \n",
       "other             194.0/0.0806          0.418  197/0.0819          0.448   \n",
       "philosophy         106.0/0.044          0.387   101/0.042          0.415   \n",
       "physics           263.0/0.1093          0.297  246/0.1022          0.426   \n",
       "psychology        175.0/0.0727          0.531  150/0.0623          0.589   \n",
       "\n",
       "                 semievol_before_filter semievol_after_filter  after/before  \\\n",
       "category                                                                      \n",
       "biology                      422/0.0585            298/0.0825         0.706   \n",
       "business                     485/0.0672            192/0.0532         0.396   \n",
       "chemistry                     686/0.095            348/0.0964         0.507   \n",
       "computer science             250/0.0346             92/0.0255         0.368   \n",
       "economics                    497/0.0688            290/0.0803         0.584   \n",
       "engineering                  598/0.0828            280/0.0776         0.468   \n",
       "health                       461/0.0639            294/0.0814         0.638   \n",
       "history                      230/0.0319            152/0.0421         0.661   \n",
       "law                          677/0.0938            279/0.0773         0.412   \n",
       "math                         825/0.1143            282/0.0781         0.342   \n",
       "other                        533/0.0738             267/0.074         0.501   \n",
       "philosophy                   292/0.0404            180/0.0499         0.616   \n",
       "physics                      790/0.1094            326/0.0903         0.413   \n",
       "psychology                   473/0.0655            330/0.0914         0.698   \n",
       "\n",
       "                  semievol_accuracy  \n",
       "category                             \n",
       "biology                       0.757  \n",
       "business                      0.418  \n",
       "chemistry                     0.474  \n",
       "computer science              0.460  \n",
       "economics                     0.536  \n",
       "engineering                   0.513  \n",
       "health                        0.613  \n",
       "history                       0.513  \n",
       "law                           0.383  \n",
       "math                          0.405  \n",
       "other                         0.412  \n",
       "philosophy                    0.443  \n",
       "physics                       0.479  \n",
       "psychology                    0.600  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_path = f\"../save/{task}__storage_home_westlakeLab_zhangshuai_models_Meta-Llama-3.1-8B-Instruct.json\"\n",
    "base_preds = []\n",
    "with open(result_path) as fo:\n",
    "    for line in fo.readlines():\n",
    "        pred = extract_result(json.loads(line)[\"response\"])\n",
    "        base_preds.append(pred)\n",
    "\n",
    "result_path = f\"../save/{task}_._sft_output_merged_warm_llama3.1_{task}.json\"\n",
    "warm_preds = []\n",
    "with open(result_path) as fo:\n",
    "    for line in fo.readlines():\n",
    "        pred = extract_result(json.loads(line)[\"response\"])\n",
    "        warm_preds.append(pred)\n",
    "        \n",
    "result_path = f\"../save/{task}_._sft_output_merged_pseudo_llama3.1_{task}_filter.json\"\n",
    "semievol_preds = []\n",
    "with open(result_path) as fo:\n",
    "    for line in fo.readlines():\n",
    "        pred = extract_result(json.loads(line)[\"response\"])\n",
    "        semievol_preds.append(pred)\n",
    "        \n",
    "path = f\"../data/{task}/test.csv\"\n",
    "test_raw_df = pd.read_csv(path)\n",
    "test_raw_df[\"base_pred\"] = base_preds\n",
    "test_raw_df[\"warm_pred\"] = warm_preds\n",
    "test_raw_df[\"semievol_pred\"] = semievol_preds\n",
    "test_raw_df[\"base_accuracy\"] = test_raw_df.apply(lambda row: int(row[\"base_pred\"] == row[\"answer\"]), axis=1)\n",
    "test_raw_df[\"warm_accuracy\"] = test_raw_df.apply(lambda row: int(row[\"warm_pred\"] == row[\"answer\"]), axis=1)\n",
    "test_raw_df[\"semievol_accuracy\"] = test_raw_df.apply(\n",
    "    lambda row: int(row[\"semievol_pred\"] == row[\"answer\"]), axis=1\n",
    ")\n",
    "\n",
    "test_summary_df = test_raw_df.groupby(subtask_name).agg(\n",
    "    test_count=(('answer', 'size')),\n",
    "    base_accuracy=('base_accuracy', 'mean'),\n",
    "    warm_accuracy=('warm_accuracy', 'mean'),\n",
    "    semievol_accuracy=('semievol_accuracy', 'mean'),\n",
    ")\n",
    "test_summary_df[\"test_proportion\"] = test_summary_df.apply(\n",
    "    lambda row: row[\"test_count\"] / test_summary_df[\"test_count\"].sum(), axis=1\n",
    ")\n",
    "\n",
    "test_summary_df = pd.merge(\n",
    "    test_summary_df, labeled_summary_df.add_prefix(\"warm_\"), on=subtask_name, how='outer'\n",
    ")\n",
    "test_summary_df = pd.merge(\n",
    "    test_summary_df, \n",
    "    unlabeled_warm_summary_df.add_prefix(\"semievol_before_filter_\"), on=subtask_name, how='outer'\n",
    ")\n",
    "test_summary_df = pd.merge(\n",
    "    test_summary_df, \n",
    "    unlabeled_filter_summary_df.add_prefix(\"semievol_after_filter_\"), on=subtask_name, how='outer'\n",
    ")\n",
    "\n",
    "for prefix in [\"test\", \"warm\", \"semievol_before_filter\", \"semievol_after_filter\"]: \n",
    "    test_summary_df[prefix] = test_summary_df.apply(\n",
    "        lambda row: f\"{row[f'{prefix}_count']}/{round(row[f'{prefix}_proportion'], 4)}\", axis=1\n",
    "    )\n",
    "    \n",
    "for prefix in [\"base\", \"warm\", \"semievol\"]:\n",
    "    test_summary_df[f\"{prefix}_accuracy\"] = test_summary_df.apply(\n",
    "        lambda row: round(row[f'{prefix}_accuracy'], 3), axis=1\n",
    "    )\n",
    "test_summary_df[\"after/before\"] = round(\n",
    "    test_summary_df[\"semievol_after_filter_count\"] / test_summary_df[\"semievol_before_filter_count\"], 3\n",
    ")\n",
    "\n",
    "test_show_summary_df = test_summary_df[[\n",
    "    \"test\", \"base_accuracy\", \n",
    "    \"warm\", \"warm_accuracy\", \n",
    "    \"semievol_before_filter\", \"semievol_after_filter\", \"after/before\", \"semievol_accuracy\"\n",
    "]]\n",
    "\n",
    "test_show_summary_df.to_csv(f\"result/{task}_test.csv\")\n",
    "test_show_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a25baf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:58:38.405265Z",
     "start_time": "2025-01-10T17:58:38.401105Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_corr_df = test_show_summary_df[[\"after/before\"]].copy()\n",
    "\n",
    "assert \"\".join(test_corr_df.index) == \"\".join(unlabeled_filter_summary_df.index)\n",
    "test_corr_df[\"filter_accuracy\"] = round(unlabeled_filter_summary_df[\"accuracy\"], 3)\n",
    "\n",
    "test_corr_df[\"delta_accuracy\"] = round(\n",
    "    test_show_summary_df[\"semievol_accuracy\"] - test_show_summary_df[\"warm_accuracy\"], 3\n",
    ")\n",
    "\n",
    "test_corr_df = test_corr_df.sort_values(by=\"after/before\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d828f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# experiment convert data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c256d34",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f714324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:49:00.044123Z",
     "start_time": "2025-01-10T16:48:59.949413Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filter acc: 0.658753709198813\n",
      "after filter acc: 0.7566643882433356\n",
      "after filter number example: 4389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3064862/199290292.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filter_pseudo_data_df = pseudo_data_df.groupby(subtask_name, group_keys=False).apply(filter_by_entropy)\n"
     ]
    }
   ],
   "source": [
    "### 过滤比例大小处于首尾的subtask以hard的方式往反方向的比例调整\n",
    "\n",
    "input_file = f\"../data/{task}/pseudo_warm_llama3.1_{task}.csv\"\n",
    "pseudo_data_df = pd.read_csv(input_file)\n",
    "\n",
    "acc = pseudo_data_df[\"Accuracy\"].sum() / len(pseudo_data_df)\n",
    "print(f\"before filter acc: {acc}\")\n",
    "\n",
    "\n",
    "keep_threshold = 11\n",
    "\n",
    "high_keep_proportion_subtask = test_corr_df[:keep_threshold].index.tolist()\n",
    "low_keep_proportion_subtask = test_corr_df[-keep_threshold:].index.tolist()\n",
    "\n",
    "\n",
    "def filter_by_entropy(group):\n",
    "    subtask = group.name\n",
    "    if subtask in low_keep_proportion_subtask:\n",
    "        threshold = group['entropy'].quantile(0.8)\n",
    "    elif subtask in high_keep_proportion_subtask:\n",
    "        threshold = group['entropy'].quantile(0.2)\n",
    "    else:\n",
    "        threshold = group['entropy'].quantile(0.5)\n",
    "    return group[group['entropy'] < threshold]\n",
    "\n",
    "filter_pseudo_data_df = pseudo_data_df.groupby(subtask_name, group_keys=False).apply(filter_by_entropy)\n",
    "\n",
    "acc = filter_pseudo_data_df[\"Accuracy\"].sum() / len(filter_pseudo_data_df)\n",
    "print(f\"after filter acc: {acc}\")\n",
    "print(f\"after filter number example: {len(filter_pseudo_data_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4429da90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:15:21.642855Z",
     "start_time": "2025-01-10T17:15:21.580251Z"
    },
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filter acc: 0.658753709198813\n",
      "after filter acc: 0.8496903287279657\n",
      "after filter number example: 4198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3086497/702062559.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filter_pseudo_data_df = pseudo_data_df.groupby(subtask_name, group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "### 按类取中位数\n",
    "\n",
    "input_file = f\"../data/{task}/pseudo_warm_llama3.1_{task}.csv\"\n",
    "pseudo_data_df = pd.read_csv(input_file)\n",
    "\n",
    "acc = pseudo_data_df[\"Accuracy\"].sum() / len(pseudo_data_df)\n",
    "print(f\"before filter acc: {acc}\")\n",
    "\n",
    "filter_pseudo_data_df = pseudo_data_df.groupby(subtask_name, group_keys=False).apply(\n",
    "    lambda group: group[group[\"entropy\"] < group['entropy'].median()]\n",
    ")\n",
    "\n",
    "acc = filter_pseudo_data_df[\"Accuracy\"].sum() / len(filter_pseudo_data_df)\n",
    "print(f\"after filter acc: {acc}\")\n",
    "print(f\"after filter number example: {len(filter_pseudo_data_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5926a1a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:10:16.043776Z",
     "start_time": "2025-01-10T16:10:15.979779Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filter acc: 0.658753709198813\n",
      "after filter acc: 0.8922374429223744\n",
      "after filter number example: 4380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2987347/3019655249.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filter_pseudo_data_df = pseudo_data_df.groupby(subtask_name, group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "### 两头挤\n",
    "\n",
    "input_file = f\"../data/{task}/pseudo_warm_llama3.1_{task}.csv\"\n",
    "pseudo_data_df = pd.read_csv(input_file)\n",
    "\n",
    "acc = pseudo_data_df[\"Accuracy\"].sum() / len(pseudo_data_df)\n",
    "print(f\"before filter acc: {acc}\")\n",
    "\n",
    "weight = 0.5\n",
    "overall_median = pseudo_data_df[\"entropy\"].median()\n",
    "filter_pseudo_data_df = pseudo_data_df.groupby(subtask_name, group_keys=False).apply(\n",
    "    lambda group: group[group[\"entropy\"] < weight * group['entropy'].median() + (1 - weight) * overall_median]\n",
    ")\n",
    "\n",
    "acc = filter_pseudo_data_df[\"Accuracy\"].sum() / len(filter_pseudo_data_df)\n",
    "print(f\"after filter acc: {acc}\")\n",
    "print(f\"after filter number example: {len(filter_pseudo_data_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe2142a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:50:55.075763Z",
     "start_time": "2025-01-10T16:50:55.034607Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filter acc: 0.658753709198813\n",
      "after filter acc: 1.0\n",
      "after filter number example: 8425\n"
     ]
    }
   ],
   "source": [
    "### 直接取groud truth看模型上限\n",
    "\n",
    "input_file = f\"../data/{task}/pseudo_warm_llama3.1_{task}.csv\"\n",
    "pseudo_data_df = pd.read_csv(input_file)\n",
    "\n",
    "acc = pseudo_data_df[\"Accuracy\"].sum() / len(pseudo_data_df)\n",
    "print(f\"before filter acc: {acc}\")\n",
    "\n",
    "filter_pseudo_data_df = pseudo_data_df.copy()\n",
    "filter_pseudo_data_df[\"PseudoLabel\"] = pseudo_data_df[\"answer\"]\n",
    "filter_pseudo_data_df[\"Accuracy\"] = 1.0\n",
    "\n",
    "acc = filter_pseudo_data_df[\"Accuracy\"].sum() / len(filter_pseudo_data_df)\n",
    "print(f\"after filter acc: {acc}\")\n",
    "print(f\"after filter number example: {len(filter_pseudo_data_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc52bcac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:15:44.325476Z",
     "start_time": "2025-01-10T17:15:44.137139Z"
    },
    "code_folding": [
     0,
     11,
     18
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def format_question_alpaca(row, format_fn=format_multichoice_question):\n",
    "    input_text = format_fn(row)\n",
    "    output_test = f'Answer: {row[\"PseudoLabel\"]}'\n",
    "\n",
    "    return {\n",
    "        \"instruction\": input_text,\n",
    "        \"input\": '',\n",
    "        \"output\": output_test,\n",
    "        \"Accuracy\": row[\"Accuracy\"],\n",
    "    }\n",
    "\n",
    "examples = [\n",
    "    format_question_alpaca(row, format_multichoice_question) \n",
    "    for _, row in filter_pseudo_data_df.iterrows()\n",
    "]\n",
    "\n",
    "output_file=f\"../sft/data/pseudo_warm_llama3.1_{task}_alpaca_threshold_by_filter_proportion.json\"\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(examples, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df0a34",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 新数据下模型的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07bb0eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:46:58.744118Z",
     "start_time": "2025-01-10T17:46:58.635356Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result_path = f\"../save/{task}_._sft_output_merged_pseudo_llama3.1_{task}_filter_threshold_by_filter_proportion.json\"\n",
    "\n",
    "semievol_threshold_preds = []\n",
    "with open(result_path) as fo:\n",
    "    for line in fo.readlines():\n",
    "        pred = extract_result(json.loads(line)[\"response\"])\n",
    "        semievol_threshold_preds.append(pred)\n",
    "\n",
    "test_threshold_df = test_raw_df.copy()[[subtask_name, \"answer\"]]\n",
    "test_threshold_df[\"semievol_threshold_pred\"] = semievol_threshold_preds\n",
    "test_threshold_df[\"semievol_threshold_accuracy\"] = test_threshold_df.apply(\n",
    "    lambda row: int(row[\"answer\"] == row[\"semievol_threshold_pred\"]), axis=1\n",
    ")\n",
    "test_threshold_summary_df = test_threshold_df.groupby(subtask_name).agg( \n",
    "    count=('semievol_threshold_accuracy', 'size'), \n",
    "    semievol_threshold_accuracy=('semievol_threshold_accuracy', 'mean')  \n",
    ")\n",
    "\n",
    "unlabeled_threshold_filter_df = pd.read_json(\n",
    "    f\"../sft/data/pseudo_warm_llama3.1_{task}_alpaca_threshold_by_filter_proportion.json\"\n",
    ")\n",
    "append_info(\n",
    "    unlabeled_threshold_filter_df, subtask_name=subtask_name, instruction_to_row=unlabel_instruction_to_row\n",
    ")\n",
    "unlabeled_threshold_filter_summary_df = unlabeled_threshold_filter_df.groupby(subtask_name).agg(\n",
    "    count=('Accuracy', 'size'), accuracy=('Accuracy', 'mean')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9492707b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:47:00.206805Z",
     "start_time": "2025-01-10T17:47:00.200807Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merge_df = pd.merge(\n",
    "    unlabeled_threshold_filter_summary_df, unlabeled_warm_summary_df, \n",
    "    on=subtask_name, how=\"inner\"\n",
    ")\n",
    "test_threshold_corr_df = pd.DataFrame({\"after/before\": round(merge_df[\"count_x\"] / merge_df[\"count_y\"], 3)})\n",
    "\n",
    "assert \"\".join(test_threshold_corr_df.index) == \"\".join(unlabeled_threshold_filter_summary_df.index)\n",
    "test_threshold_corr_df[\"filter_accuracy\"] = round(unlabeled_threshold_filter_summary_df[\"accuracy\"], 3)\n",
    "\n",
    "merge_df = pd.merge(\n",
    "    test_show_summary_df, test_threshold_summary_df, \n",
    "    on=subtask_name, how=\"inner\"\n",
    ")\n",
    "assert \"\".join(merge_df.index) == \"\".join(test_threshold_corr_df.index)\n",
    "test_threshold_corr_df[\n",
    "    \"delta_accuracy\"\n",
    "] = round(merge_df[\"semievol_threshold_accuracy\"] - merge_df[\"warm_accuracy\"], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8dd6d4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 新旧模型表现对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e70623d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:47:03.008399Z",
     "start_time": "2025-01-10T17:47:02.990099Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after/before###baseline</th>\n",
       "      <th>filter_accuracy###baseline</th>\n",
       "      <th>delta_accuracy###baseline</th>\n",
       "      <th>after/before###our</th>\n",
       "      <th>filter_accuracy###our</th>\n",
       "      <th>delta_accuracy###our</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marketing</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_psychology</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world_religions</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.0524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_government_and_politics</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.984</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us_foreign_policy</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>international_law</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.493</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virology</th>\n",
       "      <td>0.765</td>\n",
       "      <td>0.613</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_biology</th>\n",
       "      <td>0.746</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_geography</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.978</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miscellaneous</th>\n",
       "      <td>0.739</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer_security</th>\n",
       "      <td>0.736</td>\n",
       "      <td>0.897</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.885</td>\n",
       "      <td>-0.0382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_world_history</th>\n",
       "      <td>0.729</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.958</td>\n",
       "      <td>-0.0468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_genetics</th>\n",
       "      <td>0.721</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.492</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sociology</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.950</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jurisprudence</th>\n",
       "      <td>0.689</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.0473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>college_biology</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.0417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_us_history</th>\n",
       "      <td>0.675</td>\n",
       "      <td>0.901</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logical_fallacies</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.938</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.958</td>\n",
       "      <td>-0.0330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nutrition</th>\n",
       "      <td>0.668</td>\n",
       "      <td>0.920</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.0174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prehistory</th>\n",
       "      <td>0.668</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.0154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_european_history</th>\n",
       "      <td>0.657</td>\n",
       "      <td>0.940</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.941</td>\n",
       "      <td>-0.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philosophy</th>\n",
       "      <td>0.617</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.0607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_aging</th>\n",
       "      <td>0.614</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.917</td>\n",
       "      <td>-0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_sexuality</th>\n",
       "      <td>0.614</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.0591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security_studies</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinical_knowledge</th>\n",
       "      <td>0.582</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astronomy</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.932</td>\n",
       "      <td>-0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anatomy</th>\n",
       "      <td>0.577</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.0333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional_psychology</th>\n",
       "      <td>0.577</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_relations</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.857</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.839</td>\n",
       "      <td>-0.0481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>college_medicine</th>\n",
       "      <td>0.559</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_microeconomics</th>\n",
       "      <td>0.555</td>\n",
       "      <td>0.942</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.948</td>\n",
       "      <td>-0.0227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional_medicine</th>\n",
       "      <td>0.553</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.0162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_ethics</th>\n",
       "      <td>0.531</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_computer_science</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.0949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moral_disputes</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.0307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_macroeconomics</th>\n",
       "      <td>0.508</td>\n",
       "      <td>0.909</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.908</td>\n",
       "      <td>-0.0682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conceptual_physics</th>\n",
       "      <td>0.408</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electrical_engineering</th>\n",
       "      <td>0.382</td>\n",
       "      <td>0.941</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.0413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_chemistry</th>\n",
       "      <td>0.364</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.0244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>econometrics</th>\n",
       "      <td>0.351</td>\n",
       "      <td>0.808</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_statistics</th>\n",
       "      <td>0.307</td>\n",
       "      <td>0.821</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.0359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>college_chemistry</th>\n",
       "      <td>0.295</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.0433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formal_logic</th>\n",
       "      <td>0.267</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.811</td>\n",
       "      <td>-0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>college_computer_science</th>\n",
       "      <td>0.241</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.0957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moral_scenarios</th>\n",
       "      <td>0.237</td>\n",
       "      <td>0.883</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.715</td>\n",
       "      <td>-0.0862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elementary_mathematics</th>\n",
       "      <td>0.219</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.0797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional_accounting</th>\n",
       "      <td>0.218</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>college_physics</th>\n",
       "      <td>0.213</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine_learning</th>\n",
       "      <td>0.211</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.657</td>\n",
       "      <td>-0.0765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional_law</th>\n",
       "      <td>0.193</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_physics</th>\n",
       "      <td>0.145</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.0905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_facts</th>\n",
       "      <td>0.094</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.462</td>\n",
       "      <td>-0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_school_mathematics</th>\n",
       "      <td>0.071</td>\n",
       "      <td>0.909</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.494</td>\n",
       "      <td>-0.0634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_algebra</th>\n",
       "      <td>0.067</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>college_mathematics</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.1247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     after/before###baseline  \\\n",
       "Subject                                                        \n",
       "marketing                                              0.850   \n",
       "high_school_psychology                                 0.810   \n",
       "world_religions                                        0.806   \n",
       "high_school_government_and_politics                    0.803   \n",
       "us_foreign_policy                                      0.796   \n",
       "international_law                                      0.776   \n",
       "virology                                               0.765   \n",
       "high_school_biology                                    0.746   \n",
       "high_school_geography                                  0.742   \n",
       "miscellaneous                                          0.739   \n",
       "computer_security                                      0.736   \n",
       "high_school_world_history                              0.729   \n",
       "medical_genetics                                       0.721   \n",
       "sociology                                              0.690   \n",
       "jurisprudence                                          0.689   \n",
       "college_biology                                        0.680   \n",
       "high_school_us_history                                 0.675   \n",
       "logical_fallacies                                      0.670   \n",
       "nutrition                                              0.668   \n",
       "prehistory                                             0.668   \n",
       "management                                             0.667   \n",
       "high_school_european_history                           0.657   \n",
       "philosophy                                             0.617   \n",
       "human_aging                                            0.614   \n",
       "human_sexuality                                        0.614   \n",
       "security_studies                                       0.594   \n",
       "clinical_knowledge                                     0.582   \n",
       "astronomy                                              0.580   \n",
       "anatomy                                                0.577   \n",
       "professional_psychology                                0.577   \n",
       "public_relations                                       0.565   \n",
       "college_medicine                                       0.559   \n",
       "high_school_microeconomics                             0.555   \n",
       "professional_medicine                                  0.553   \n",
       "business_ethics                                        0.531   \n",
       "high_school_computer_science                           0.525   \n",
       "moral_disputes                                         0.517   \n",
       "high_school_macroeconomics                             0.508   \n",
       "conceptual_physics                                     0.408   \n",
       "electrical_engineering                                 0.382   \n",
       "high_school_chemistry                                  0.364   \n",
       "econometrics                                           0.351   \n",
       "high_school_statistics                                 0.307   \n",
       "college_chemistry                                      0.295   \n",
       "formal_logic                                           0.267   \n",
       "college_computer_science                               0.241   \n",
       "moral_scenarios                                        0.237   \n",
       "elementary_mathematics                                 0.219   \n",
       "professional_accounting                                0.218   \n",
       "college_physics                                        0.213   \n",
       "machine_learning                                       0.211   \n",
       "professional_law                                       0.193   \n",
       "high_school_physics                                    0.145   \n",
       "global_facts                                           0.094   \n",
       "high_school_mathematics                                0.071   \n",
       "abstract_algebra                                       0.067   \n",
       "college_mathematics                                    0.032   \n",
       "\n",
       "                                     filter_accuracy###baseline  \\\n",
       "Subject                                                           \n",
       "marketing                                                 0.923   \n",
       "high_school_psychology                                    0.951   \n",
       "world_religions                                           0.908   \n",
       "high_school_government_and_politics                       0.961   \n",
       "us_foreign_policy                                         0.930   \n",
       "international_law                                         0.962   \n",
       "virology                                                  0.613   \n",
       "high_school_biology                                       0.884   \n",
       "high_school_geography                                     0.978   \n",
       "miscellaneous                                             0.957   \n",
       "computer_security                                         0.897   \n",
       "high_school_world_history                                 0.952   \n",
       "medical_genetics                                          0.955   \n",
       "sociology                                                 0.950   \n",
       "jurisprudence                                             0.952   \n",
       "college_biology                                           0.924   \n",
       "high_school_us_history                                    0.901   \n",
       "logical_fallacies                                         0.938   \n",
       "nutrition                                                 0.920   \n",
       "prehistory                                                0.898   \n",
       "management                                                0.889   \n",
       "high_school_european_history                              0.940   \n",
       "philosophy                                                0.926   \n",
       "human_aging                                               0.899   \n",
       "human_sexuality                                           0.907   \n",
       "security_studies                                          0.924   \n",
       "clinical_knowledge                                        0.921   \n",
       "astronomy                                                 0.882   \n",
       "anatomy                                                   0.889   \n",
       "professional_psychology                                   0.891   \n",
       "public_relations                                          0.857   \n",
       "college_medicine                                          0.894   \n",
       "high_school_microeconomics                                0.942   \n",
       "professional_medicine                                     0.933   \n",
       "business_ethics                                           0.941   \n",
       "high_school_computer_science                              0.969   \n",
       "moral_disputes                                            0.943   \n",
       "high_school_macroeconomics                                0.909   \n",
       "conceptual_physics                                        0.817   \n",
       "electrical_engineering                                    0.941   \n",
       "high_school_chemistry                                     0.907   \n",
       "econometrics                                              0.808   \n",
       "high_school_statistics                                    0.821   \n",
       "college_chemistry                                         0.833   \n",
       "formal_logic                                              0.950   \n",
       "college_computer_science                                  0.923   \n",
       "moral_scenarios                                           0.883   \n",
       "elementary_mathematics                                    0.885   \n",
       "professional_accounting                                   0.811   \n",
       "college_physics                                           1.000   \n",
       "machine_learning                                          0.867   \n",
       "professional_law                                          0.782   \n",
       "high_school_physics                                       0.818   \n",
       "global_facts                                              0.600   \n",
       "high_school_mathematics                                   0.909   \n",
       "abstract_algebra                                          1.000   \n",
       "college_mathematics                                       0.500   \n",
       "\n",
       "                                     delta_accuracy###baseline  \\\n",
       "Subject                                                          \n",
       "marketing                                                0.048   \n",
       "high_school_psychology                                   0.035   \n",
       "world_religions                                          0.000   \n",
       "high_school_government_and_politics                      0.055   \n",
       "us_foreign_policy                                        0.000   \n",
       "international_law                                        0.042   \n",
       "virology                                                -0.029   \n",
       "high_school_biology                                      0.080   \n",
       "high_school_geography                                   -0.056   \n",
       "miscellaneous                                            0.000   \n",
       "computer_security                                       -0.077   \n",
       "high_school_world_history                               -0.024   \n",
       "medical_genetics                                         0.095   \n",
       "sociology                                               -0.028   \n",
       "jurisprudence                                            0.047   \n",
       "college_biology                                          0.083   \n",
       "high_school_us_history                                  -0.022   \n",
       "logical_fallacies                                       -0.033   \n",
       "nutrition                                               -0.018   \n",
       "prehistory                                               0.031   \n",
       "management                                               0.000   \n",
       "high_school_european_history                            -0.027   \n",
       "philosophy                                               0.085   \n",
       "human_aging                                              0.000   \n",
       "human_sexuality                                          0.147   \n",
       "security_studies                                         0.000   \n",
       "clinical_knowledge                                       0.060   \n",
       "astronomy                                                0.028   \n",
       "anatomy                                                  0.000   \n",
       "professional_psychology                                  0.009   \n",
       "public_relations                                        -0.048   \n",
       "college_medicine                                         0.031   \n",
       "high_school_microeconomics                              -0.023   \n",
       "professional_medicine                                    0.032   \n",
       "business_ethics                                          0.143   \n",
       "high_school_computer_science                             0.095   \n",
       "moral_disputes                                           0.046   \n",
       "high_school_macroeconomics                              -0.054   \n",
       "conceptual_physics                                       0.081   \n",
       "electrical_engineering                                  -0.042   \n",
       "high_school_chemistry                                    0.024   \n",
       "econometrics                                            -0.105   \n",
       "high_school_statistics                                  -0.019   \n",
       "college_chemistry                                        0.043   \n",
       "formal_logic                                             0.087   \n",
       "college_computer_science                                 0.048   \n",
       "moral_scenarios                                         -0.108   \n",
       "elementary_mathematics                                   0.066   \n",
       "professional_accounting                                  0.039   \n",
       "college_physics                                          0.000   \n",
       "machine_learning                                         0.000   \n",
       "professional_law                                         0.037   \n",
       "high_school_physics                                      0.045   \n",
       "global_facts                                            -0.118   \n",
       "high_school_mathematics                                 -0.016   \n",
       "abstract_algebra                                        -0.154   \n",
       "college_mathematics                                     -0.083   \n",
       "\n",
       "                                     after/before###our  \\\n",
       "Subject                                                   \n",
       "marketing                                         0.497   \n",
       "high_school_psychology                            0.500   \n",
       "world_religions                                   0.500   \n",
       "high_school_government_and_politics               0.496   \n",
       "us_foreign_policy                                 0.500   \n",
       "international_law                                 0.493   \n",
       "virology                                          0.500   \n",
       "high_school_biology                               0.497   \n",
       "high_school_geography                             0.500   \n",
       "miscellaneous                                     0.500   \n",
       "computer_security                                 0.491   \n",
       "high_school_world_history                         0.500   \n",
       "medical_genetics                                  0.492   \n",
       "sociology                                         0.500   \n",
       "jurisprudence                                     0.492   \n",
       "college_biology                                   0.495   \n",
       "high_school_us_history                            0.500   \n",
       "logical_fallacies                                 0.495   \n",
       "nutrition                                         0.497   \n",
       "prehistory                                        0.500   \n",
       "management                                        0.500   \n",
       "high_school_european_history                      0.500   \n",
       "philosophy                                        0.497   \n",
       "human_aging                                       0.497   \n",
       "human_sexuality                                   0.500   \n",
       "security_studies                                  0.497   \n",
       "clinical_knowledge                                0.484   \n",
       "astronomy                                         0.500   \n",
       "anatomy                                           0.500   \n",
       "professional_psychology                           0.499   \n",
       "public_relations                                  0.500   \n",
       "college_medicine                                  0.517   \n",
       "high_school_microeconomics                        0.497   \n",
       "professional_medicine                             0.497   \n",
       "business_ethics                                   0.500   \n",
       "high_school_computer_science                      0.492   \n",
       "moral_disputes                                    0.498   \n",
       "high_school_macroeconomics                        0.500   \n",
       "conceptual_physics                                0.497   \n",
       "electrical_engineering                            0.494   \n",
       "high_school_chemistry                             0.500   \n",
       "econometrics                                      0.500   \n",
       "high_school_statistics                            0.496   \n",
       "college_chemistry                                 0.492   \n",
       "formal_logic                                      0.493   \n",
       "college_computer_science                          0.500   \n",
       "moral_scenarios                                   0.499   \n",
       "elementary_mathematics                            0.498   \n",
       "professional_accounting                           0.500   \n",
       "college_physics                                   0.492   \n",
       "machine_learning                                  0.493   \n",
       "professional_law                                  0.500   \n",
       "high_school_physics                               0.500   \n",
       "global_facts                                      0.491   \n",
       "high_school_mathematics                           0.500   \n",
       "abstract_algebra                                  0.500   \n",
       "college_mathematics                               0.500   \n",
       "\n",
       "                                     filter_accuracy###our  \\\n",
       "Subject                                                      \n",
       "marketing                                            0.961   \n",
       "high_school_psychology                               0.988   \n",
       "world_religions                                      0.944   \n",
       "high_school_government_and_politics                  0.984   \n",
       "us_foreign_policy                                    1.000   \n",
       "international_law                                    1.000   \n",
       "virology                                             0.673   \n",
       "high_school_biology                                  0.946   \n",
       "high_school_geography                                1.000   \n",
       "miscellaneous                                        0.987   \n",
       "computer_security                                    0.885   \n",
       "high_school_world_history                            0.958   \n",
       "medical_genetics                                     1.000   \n",
       "sociology                                            0.966   \n",
       "jurisprudence                                        0.967   \n",
       "college_biology                                      0.979   \n",
       "high_school_us_history                               0.950   \n",
       "logical_fallacies                                    0.958   \n",
       "nutrition                                            0.968   \n",
       "prehistory                                           0.958   \n",
       "management                                           0.963   \n",
       "high_school_european_history                         0.941   \n",
       "philosophy                                           0.954   \n",
       "human_aging                                          0.917   \n",
       "human_sexuality                                      0.943   \n",
       "security_studies                                     0.948   \n",
       "clinical_knowledge                                   0.959   \n",
       "astronomy                                            0.932   \n",
       "anatomy                                              0.897   \n",
       "professional_psychology                              0.905   \n",
       "public_relations                                     0.839   \n",
       "college_medicine                                     0.918   \n",
       "high_school_microeconomics                           0.948   \n",
       "professional_medicine                                0.938   \n",
       "business_ethics                                      0.938   \n",
       "high_school_computer_science                         0.967   \n",
       "moral_disputes                                       0.950   \n",
       "high_school_macroeconomics                           0.908   \n",
       "conceptual_physics                                   0.767   \n",
       "electrical_engineering                               0.864   \n",
       "high_school_chemistry                                0.847   \n",
       "econometrics                                         0.730   \n",
       "high_school_statistics                               0.762   \n",
       "college_chemistry                                    0.633   \n",
       "formal_logic                                         0.811   \n",
       "college_computer_science                             0.741   \n",
       "moral_scenarios                                      0.715   \n",
       "elementary_mathematics                               0.737   \n",
       "professional_accounting                              0.718   \n",
       "college_physics                                      0.800   \n",
       "machine_learning                                     0.657   \n",
       "professional_law                                     0.656   \n",
       "high_school_physics                                  0.579   \n",
       "global_facts                                         0.462   \n",
       "high_school_mathematics                              0.494   \n",
       "abstract_algebra                                     0.433   \n",
       "college_mathematics                                  0.452   \n",
       "\n",
       "                                     delta_accuracy###our  \n",
       "Subject                                                    \n",
       "marketing                                          0.0001  \n",
       "high_school_psychology                             0.0083  \n",
       "world_religions                                    0.0524  \n",
       "high_school_government_and_politics               -0.0001  \n",
       "us_foreign_policy                                 -0.0004  \n",
       "international_law                                  0.0417  \n",
       "virology                                           0.0002  \n",
       "high_school_biology                                0.0800  \n",
       "high_school_geography                             -0.0004  \n",
       "miscellaneous                                      0.0002  \n",
       "computer_security                                 -0.0382  \n",
       "high_school_world_history                         -0.0468  \n",
       "medical_genetics                                   0.0948  \n",
       "sociology                                         -0.0001  \n",
       "jurisprudence                                      0.0473  \n",
       "college_biology                                    0.0417  \n",
       "high_school_us_history                             0.0000  \n",
       "logical_fallacies                                 -0.0330  \n",
       "nutrition                                          0.0174  \n",
       "prehistory                                         0.0154  \n",
       "management                                         0.0003  \n",
       "high_school_european_history                      -0.0274  \n",
       "philosophy                                         0.0607  \n",
       "human_aging                                       -0.0005  \n",
       "human_sexuality                                    0.0591  \n",
       "security_studies                                   0.0003  \n",
       "clinical_knowledge                                 0.0400  \n",
       "astronomy                                         -0.0002  \n",
       "anatomy                                            0.0333  \n",
       "professional_psychology                            0.0002  \n",
       "public_relations                                  -0.0481  \n",
       "college_medicine                                   0.0310  \n",
       "high_school_microeconomics                        -0.0227  \n",
       "professional_medicine                              0.0162  \n",
       "business_ethics                                    0.1429  \n",
       "high_school_computer_science                       0.0949  \n",
       "moral_disputes                                     0.0307  \n",
       "high_school_macroeconomics                        -0.0682  \n",
       "conceptual_physics                                 0.0808  \n",
       "electrical_engineering                             0.0413  \n",
       "high_school_chemistry                              0.0244  \n",
       "econometrics                                      -0.0001  \n",
       "high_school_statistics                             0.0359  \n",
       "college_chemistry                                  0.0433  \n",
       "formal_logic                                      -0.0003  \n",
       "college_computer_science                           0.0957  \n",
       "moral_scenarios                                   -0.0862  \n",
       "elementary_mathematics                             0.0797  \n",
       "professional_accounting                            0.0392  \n",
       "college_physics                                    0.0004  \n",
       "machine_learning                                  -0.0765  \n",
       "professional_law                                   0.0185  \n",
       "high_school_physics                                0.0905  \n",
       "global_facts                                      -0.1179  \n",
       "high_school_mathematics                           -0.0634  \n",
       "abstract_algebra                                  -0.0772  \n",
       "college_mathematics                               -0.1247  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corr_compare_df = pd.merge(\n",
    "    test_corr_df, test_threshold_corr_df, on=subtask_name, how=\"left\", suffixes=(\"###baseline\", \"###our\")\n",
    ")\n",
    "test_corr_compare_df.to_csv(f\"result/{task}_test_compare.csv\")\n",
    "test_corr_compare_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semi_instruction_tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
